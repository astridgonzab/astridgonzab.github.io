---
title: "Regresi贸n Lineal M煤ltiple"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_download: true
    theme: lumen 
    toc_depth: 3 
    css: styles.css             
---
```{r, echo=FALSE,warning=FALSE}
library(readxl)
library(knitr)     
library(kableExtra)
library(DT)
library(lmtest)
```

# **1. Datos**

```{r, warning=FALSE}
caso3 <- read_excel("C:/Users/User/Downloads/Caso3.xlsx")
colnames(caso3) <- c("ID_Pedido", "Distancia_km", "Num_Paquetes", "Velocidad_Trafico", "Tiempo_Entrega_min")
datatable(caso3, 
          options = list(pageLength = 5, 
                         autoWidth = TRUE),
          caption = "Tabla 1. Datos de Pedidos",
          rownames = FALSE, 
          class = 'display', 
          escape = FALSE) %>%
  formatStyle(
    columns = names(caso3),
    border = 'solid 1px black', 
    textAlign = 'center'  
  ) %>%
  formatStyle(
    colnames(caso3),
    border = 'solid 1px black', 
    textAlign = 'center' 
  )
```

El conjunto de datos consta de 4 variables relevantes: Distancia_km, Num_Paquetes, Velocidad_Trafico y Tiempo_Entrega_min, con un total de 20 observaciones, siendo el ID_Pedido solo un identificador sin relevancia en el an谩lisis. La situaci贸n aborda la operaci贸n log铆stica de entrega de pedidos a domicilio, considerando diversos factores que podr铆an influir en el tiempo total de entrega.

## **1.2 . Contexto y objetivo**

En este estudio se busca predecir el tiempo de entrega de pedidos a domicilio a partir de caracter铆sticas asociadas a la operaci贸n log铆stica. La empresa dispone de informaci贸n sobre diversos factores que pueden afectar el tiempo total de entrega, como la distancia recorrida, el n煤mero de paquetes transportados y las condiciones del tr谩fico. Para modelar esta situaci贸n, se plantea un an谩lisis de regresi贸n lineal m煤ltiple, utilizando como:

**Variable dependiente:**

- **Tiempo_Entrega_min:** Tiempo que tarda en completarse cada entrega (en minutos).

**Variables independientes:**

- **Distancia_km:** Distancia recorrida desde el punto de despacho hasta el destino (en kil贸metros).

- **Num_Paquetes:** N煤mero de paquetes incluidos en el pedido.

- **Velocidad_Trafico:** Velocidad promedio del tr谩fico en la ruta de entrega (en kil贸metros por hora).

Este an谩lisis permitir谩 comprender c贸mo influyen estos factores en los tiempos de entrega y construir un modelo que facilite la predicci贸n precisa de futuros pedidos, mejorando la eficiencia log铆stica y la satisfacci贸n del cliente.

# **2.  Ecuaci贸n de regresi贸n ajustada e interpretaci贸n de los par谩metros**

```{r}
# Ajustar el modelo de regresi贸n lineal m煤ltiple
modelo <- lm(Tiempo_Entrega_min ~ Distancia_km + Num_Paquetes + Velocidad_Trafico, data = caso3)

# Ver el resumen del modelo
summary(modelo)
```
A partir de la salida del modelo de regresi贸n lineal ajustado en R, obtenemos la siguiente ecuaci贸n de la recta ajustada:

$$
\text{Tiempo_Entrega_min} = 40.5191 + 0.3645 \times \text{Distancia_km} + 1.7958 \times \text{Num_Paquetes} - 0.1361 \times \text{Velocidad_Trafico}
$$

En donde: 

- **Par谩metro \( b_0 = 40.5191 \) (Intercepto)**: El intercepto de 40.5191 representa el **tiempo de entrega base** cuando todas las variables independientes (distancia, n煤mero de paquetes y velocidad del tr谩fico) son cero. Es decir, si la distancia fuera cero, no hubiera paquetes y la velocidad del tr谩fico fuera cero, el tiempo de entrega ser铆a de **40.5191 minutos**.

- **Par谩metro \( b_1 = 0.3645 \) (Distancia_km)**: Este par谩metro indica que **por cada kil贸metro adicional** en la distancia de entrega, el tiempo de entrega aumentar谩 en promedio **0.3645 minutos**. 

- **Par谩metro \( b_2 = 1.7958 \) (Num_Paquetes)**: Este par谩metro muestra que **por cada paquete adicional** en el pedido, el tiempo de entrega aumentar谩 en promedio **1.7958 minutos**. 

- **Par谩metro \( b_3 = -0.1361 \) (Velocidad_Trafico)**: Este par谩metro indica que **por cada aumento de 1 km/h en la velocidad del tr谩fico**, el tiempo de entrega disminuir谩 en promedio **0.1361 minutos**.

# **3. Pron贸sticar el tiempo de entrega de un pedido que debe recorrer 18 kil贸metros, lleva 10 paquetes y el tr谩fico es de 40Km/h.**

```{r}
# Definir los par谩metros de la regresi贸n
b0 <- 40.5191
b1 <- 0.3645
b2 <- 1.7958
b3 <- -0.1361

# Vector con los valores de las variables
Distancia_km <- 18
Num_Paquetes <- 10
Velocidad_Trafico <- 40

# C谩lculo del tiempo de entrega 
tiempo_entrega <- b0 + b1 * Distancia_km + b2 * Num_Paquetes + b3 * Velocidad_Trafico

cat("El tiempo de entrega pronosticado es: ", round(tiempo_entrega, 2), " minutos\n")
```

# **4.  Anova**

El ANOVA en regresi贸n lineal se utiliza para analizar c贸mo las variables independientes, como Distancia_km, Num_Paquetes y Velocidad_Trafico, contribuyen a la variabilidad del Tiempo_Entrega_min. Este an谩lisis descompone la variabilidad total en dos partes: una explicada por el modelo, a trav茅s de las variables predictoras, y otra atribuida al error, que representa la variabilidad no explicada por el modelo.

```{r}
anova <- anova(modelo)
anova
```

El ANOVA se realiz贸 para analizar c贸mo las tres variables independientes (Distancia_km, Num_Paquetes, y Velocidad_Trafico) afectan el Tiempo_Entrega_min. Al combinar la informaci贸n de las variables independientes, se obtuvo una 煤nica Suma de Cuadrados de la Regresi贸n (SCR), Media Cuadr谩tica de la Regresi贸n (MCR) y sus correspondientes grados de libertad. Estos valores se sumaron para formar la base del an谩lisis y calcular el valor F, que nos permite evaluar la significancia global del modelo. A continuaci贸n, se presenta la tabla con los resultados del ANOVA, mostrando c贸mo las variables y el error contribuyen a la variabilidad total del tiempo de entrega.

```{r}
# Suma de Cuadrados Total (SCT)
sct <- sum((caso3$Tiempo_Entrega_min - mean(caso3$Tiempo_Entrega_min))^2)  # Suma de Cuadrados Total

# Suma de Cuadrados de la Regresi贸n (SCR)
scr <- sum((fitted(modelo) - mean(caso3$Tiempo_Entrega_min))^2)  # Suma de Cuadrados de la Regresi贸n

# Suma de Cuadrados del Error (SCE)
sce <- sct - scr  # Suma de Cuadrados del Error

# Grados de libertad
df_reg <- length(coef(modelo)) - 1  # N煤mero de variables predictoras (sin contar el intercepto)
df_error <- length(caso3$Tiempo_Entrega_min) - df_reg - 1
df_total <- length(caso3$Tiempo_Entrega_min) - 1

# Media cuadr谩tica de la regresi贸n (MCR) y media cuadr谩tica del error (MCE)
mcr <- scr / df_reg
mce <- sce / df_error

# C谩lculo del valor F
f_value <- mcr / mce

# P-valor asociado al valor F
p_value <- 1 - pf(f_value, df_reg, df_error)
p_value_formatted <- format(p_value, scientific = TRUE, digits = 4)

resultados_anova <- data.frame(
  Fuente = c("Regresi贸n (Modelo)", "Error (Residuos)", "Total"),
  Suma_Cuadrados = c(scr, sce, sct),
  Grados_de_Libertad = c(df_reg, df_error, df_total),
  Media_Cuadr谩tica = c(mcr, mce, NA),
  Valor_F = c(f_value, NA, NA),
  P_Valor = c(p_value_formatted, NA, NA)
)

resultados_anova %>%
  kable("html", caption = "Resultados del ANOVA para el Modelo de Regresi贸n", align = "c", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "responsive"), full_width = FALSE, position = "center") %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE, background = "#DBDBDB") %>%
  row_spec(1:2, background = "white") %>%
  kable_styling(bootstrap_options = "condensed", full_width = FALSE)
```

# **5.  Prueba Global**

La prueba global se realiza para evaluar si las variables independientes (Distancia_km, Num_Paquetes y Velocidad_Trafico) tienen un impacto significativo sobre el Tiempo_Entrega_min. A trav茅s de esta prueba comparamos la variabilidad explicada por el modelo con la variabilidad no explicada (error) y, usando el estad铆stico F y el p-valor, determinamos si el modelo en su conjunto es relevante para predecir el tiempo de entrega.

## **1. Formulaci贸n de hip贸tesis**

- **Hip贸tesis nula (\(H_0\))**:  
  \[
  H_0: \beta_1 = \beta_2 = \beta_3 = 0
  \]  
  Esto significa que **ninguna** de las variables independientes tiene un efecto significativo sobre el **Tiempo_Entrega_min**.

- **Hip贸tesis alternativa (\(H_1\))**:  
  \[
  H_1: \text{Al menos uno de los coeficientes } \beta_i \neq 0
  \]  
  
Esto significa que **al menos una de las variables** tiene un efecto significativo sobre el **Tiempo_Entrega_min**.

## **2. Nivel de significancia**

El **nivel de significancia** (\(\alpha\)) es el umbral que utilizamos para decidir si podemos rechazar la **hip贸tesis nula**. En este caso, hemos establecido el nivel de significancia en \( \alpha = 0.05 \), lo que significa que si el **p-valor** calculado es menor que 0.05, rechazamos la hip贸tesis nula y concluimos que al menos una de las variables independientes tiene un efecto significativo sobre el **Tiempo_Entrega_min**.

## **3. Estad铆stico de prueba**

Para esto tenemos en cuenta lo siguiente: 

$$
F = \frac{\frac{\text{Suma de Cuadrados de la Regresi贸n (SCR)}}{\text{df}_{\text{reg}}}}{\frac{\text{Suma de Cuadrados del Error (SCE)}}{\text{df}_{\text{error}}}}
$$
por tanto: 

```{r}
anova_resultado <- anova(modelo)

# Obtener las sumas de cuadrados de la regresi贸n (SCR) y del error (SCE)
scr <- anova_resultado$`Sum Sq`[1] + anova_resultado$`Sum Sq`[2] + anova_resultado$`Sum Sq`[3] # Suma de Cuadrados de la Regresi贸n
sce <- anova_resultado$`Sum Sq`[4]  # Suma de Cuadrados del Error

# Obtener los grados de libertad de la regresi贸n (df_reg) y del error (df_error)
df_reg <- anova_resultado$Df[1] + anova_resultado$Df[2] + anova_resultado$Df[3] # Grados de libertad de la regresi贸n
df_error <- anova_resultado$Df[4]  # Grados de libertad del error

# C谩lculo del valor F
valor_F <- (scr / df_reg) / (sce / df_error)
cat("El valor F calculado es:", round(valor_F, 2), "\n")
```

Es decir: 

$$
F = \frac{\frac{\text{SCR}}{\text{df}_{\text{reg}}}}{\frac{\text{SCE}}{\text{df}_{\text{error}}}} = \frac{\frac{1332.227}{3}}{\frac{446.973}{16}} = 15.9
$$

## **4. Criterio de decisi贸n**

```{r}
# Calcular el valor p asociado al valor F
p_value <- 1 - pf(valor_F, df_reg, df_error)

cat("El valor p asociado al valor F calculado es:", format(p_value, scientific = TRUE), "\n")
```

## **5. Interpretaci贸n**

Si el valor p es menor que el nivel de significancia \(\alpha = 0.05\), rechazamos la hip贸tesis nula (\(H_0\)) y concluimos que **al menos una de las variables independientes** tiene un impacto significativo sobre el **Tiempo_Entrega_min**. En caso contrario, si el valor p es mayor o igual a 0.05, no rechazamos la hip贸tesis nula. En nuestro caso, el valor p calculado es \(4.67 \times 10^{-5}\), que es menor que \(\alpha = 0.05\). Por lo tanto, **rechazamos la hip贸tesis nula** y concluimos que el modelo es significativo.

## **6. Conclusi贸n**

El valor p asociado al valor F calculado es 4.67e-05, mucho menor que el nivel de significancia de 0.05, lo que sugiere que el modelo en su conjunto es relevante, ya que existe una relaci贸n significativa entre las variables independientes y el Tiempo_Entrega_min, lo que indica que al menos una de las variables tiene un impacto importante en la predicci贸n del tiempo de entrega.

# **6.  Pruebas individuales sobre las variables**

A diferencia de la prueba global, que eval煤a el impacto conjunto de todas las variables, en esta secci贸n analizamos cada variable independiente por separado. Para cada una, comparamos el valor p con el nivel de significancia (= 0.05 para determinar si rechazamos la hip贸tesis nula y concluimos que la variable tiene un impacto significativo sobre el Tiempo_Entrega_min.

```{r}
# Resumen del modelo
summary_resultado <- summary(modelo)

# Extraer coeficientes, valores p y grados de libertad
coeficientes <- summary_resultado$coefficients

# Nivel de significancia
alpha <- 0.05

hipotesis_table <- data.frame(
  Variable = c("Distancia_km", "Num_Paquetes", "Velocidad_Trafico"),
  Hipotesis_nula = c("$H_0: \\beta_1 = 0$", "$H_0: \\beta_2 = 0$", "$H_0: \\beta_3 = 0$"),
  Hipotesis_alternativa = c("$H_1: \\beta_1 \\neq 0$", "$H_1: \\beta_2 \\neq 0$", "$H_1: \\beta_3 \\neq 0$"),
  Nivel_significancia = rep("0.05", 3),
  Valor_t = c(coeficientes[2, 3], coeficientes[3, 3], coeficientes[4, 3]),  # Valores t
  df = c(summary_resultado$df[2], summary_resultado$df[2], summary_resultado$df[2]),  # Grados de libertad
  Valor_p = c(coeficientes[2, 4], coeficientes[3, 4], coeficientes[4, 4]),
  Comparacion = c(
    ifelse(coeficientes[2, 4] < alpha, "Valor p < alfa", "Valor p > alfa"),
    ifelse(coeficientes[3, 4] < alpha, "Valor p < alfa", "Valor p > alfa"),
    ifelse(coeficientes[4, 4] < alpha, "Valor p < alfa", "Valor p > alfa")
  ),
  Decisi贸n = c(
    ifelse(coeficientes[2, 4] < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$"),
    ifelse(coeficientes[3, 4] < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$"),
    ifelse(coeficientes[4, 4] < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$")
  ),
  stringsAsFactors = FALSE
)

hipotesis_table %>%
  kable("html", caption = "Prueba de Hip贸tesis para las Variables Independientes", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE, position = "center")
```

En el an谩lisis de las pruebas de hip贸tesis, se observ贸 que el n煤mero de paquetes es la 煤nica variable que tiene un impacto significativo en el tiempo de entrega de los pedidos, con un valor p de 0.0165, lo que nos permite rechazar la hip贸tesis nula. Esto sugiere que, a medida que aumenta el n煤mero de paquetes, el tiempo de entrega tambi茅n se incrementa de manera notable. Por otro lado, tanto la distancia recorrida como la velocidad del tr谩fico no muestran una relaci贸n significativa con el tiempo de entrega, ya que sus valores p son 0.2246 y 0.6796 respectivamente, ambos mayores que el nivel de significancia de 0.05, lo que significa que no hay suficiente evidencia para afirmar que estas variables influyan de manera relevante en el tiempo de entrega. En resumen, el n煤mero de paquetes emerge como el factor m谩s determinante en el tiempo de entrega, mientras que la distancia y la velocidad del tr谩fico no parecen tener un impacto considerable, al menos dentro del contexto de este modelo de regresi贸n.

# **7.  Coeficiente de determinaci贸n**

```{r}
# C谩lculo de las sumas de cuadrados
sce <- sum(anova_resultado$`Sum Sq`[4]) 
sct <- sum(anova_resultado$`Sum Sq`)     

# N煤mero de observaciones y predictores
n <- length(caso3$Tiempo_Entrega_min)
k <- length(coef(modelo)) - 1  # N煤mero de predictores (sin contar el intercepto)

# C谩lculo para R^2 ajustado
r_squared_ajustado <- 1 - ((sce / (n - k - 1)) / (sct / (n - 1)))

cat("El valor de R^2 ajustado es:", round(r_squared_ajustado, 4), "\n")
```

El \( R^2_{\text{ajustado}} = 0.7017 \) indica que el **70.17%** de la variabilidad en el **Tiempo_Entrega_min** es explicada por las variables del modelo. Este valor refleja un ajuste razonable del modelo, sugiriendo que las variables seleccionadas tienen un impacto notable en la predicci贸n del tiempo de entrega. Sin embargo, hay un porcentaje significativo de la variabilidad (aproximadamente el **29.83%**) que no est谩 siendo explicado por el modelo, lo que sugiere que hay otros factores no contemplados en el an谩lisis.

# **8.  Coeficiente de correlaci贸n de Pearson**

```{r}
correlacion <- sqrt(r_squared_ajustado)
cat("El coeficiente de correlaci贸n es:",round(correlacion, 4))
```

El coeficiente de correlaci贸n de 0.8377 indica una relaci贸n fuerte y positiva (directa) entre las variables, esto significa que, en general, cuando una variable aumenta, el tiempo de entrega tambi茅n tiende a aumentar. Aunque este valor refleja una relaci贸n lineal entre las variables, es importante recordar que se trata de una correlaci贸n m煤ltiple, lo que significa que esta relaci贸n involucra el comportamiento conjunto de todas las variables del modelo. Para verificar mejor esta correlaci贸n, se realizar谩 un an谩lisis detallado de cada variable independiente en relaci贸n con la variable dependiente.

```{r}
# Matriz de correlaci贸n entre las variables
correlaciones <- cor(caso3[, c("Distancia_km", "Num_Paquetes", "Velocidad_Trafico", "Tiempo_Entrega_min")])

correlaciones %>%
  kable("html", caption = "Matriz de Correlaci贸n entre las Variables", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE, position = "center")
```
En la matriz de correlaci贸n se puede observar que todas las relaciones entre las variables independientes y la variable dependiente, Tiempo_Entrega_min, son directas, lo que significa que a medida que aumenta el valor de una variable independiente, el tiempo de entrega tambi茅n tiende a aumentar.

La relaci贸n entre Distancia_km y Tiempo_Entrega_min tiene una correlaci贸n de 0.7857, lo que indica una relaci贸n positiva moderada a fuerte, esto significa que, en general, cuando la distancia recorrida aumenta, tambi茅n lo hace el tiempo de entrega, lo cual tiene sentido en t茅rminos log铆sticos.

Con respecto a Num_Paquetes y Tiempo_Entrega_min, la correlaci贸n es a煤n m谩s fuerte (0.8506), lo que refleja una relaci贸n directa muy fuerte, a medida que el n煤mero de paquetes en el pedido crece, el tiempo de entrega aumenta significativamente, lo que es esperado debido al mayor esfuerzo log铆stico requerido para manejar m谩s paquetes.

Por 煤ltimo, la relaci贸n entre Velocidad_Trafico y Tiempo_Entrega_min tiene una correlaci贸n de 0.7243, lo que indica una relaci贸n positiva moderada a fuerte, aunque no tan fuerte como las otras dos relaciones, a煤n muestra que un aumento en la velocidad del tr谩fico puede llevar a un mayor tiempo de entrega, aunque con un impacto m谩s peque帽o en comparaci贸n con las otras variables.

En resumen, todas las correlaciones observadas son directas, lo que significa que un aumento en las variables independientes tiende a resultar en un aumento del tiempo de entrega, aunque la intensidad de la relaci贸n var铆a entre ellas.

# **9.  Prueba de hip贸tesis para coeficiente de correlaci贸n**

```{r}
# Pruebas de correlaci贸n de Pearson entre las variables
cor_test_1 <- cor.test(caso3$Distancia_km, caso3$Tiempo_Entrega_min, method = "pearson")
cor_test_2 <- cor.test(caso3$Num_Paquetes, caso3$Tiempo_Entrega_min, method = "pearson")
cor_test_3 <- cor.test(caso3$Velocidad_Trafico, caso3$Tiempo_Entrega_min, method = "pearson")

# Tabla de resultados de la prueba de hip贸tesis para cada par de variables
hipotesis_table_correlacion <- data.frame(
  Variable_1 = c("Distancia_km", "Num_Paquetes", "Velocidad_Trafico"),
  Variable_2 = rep("Tiempo_Entrega_min", 3),
  Hipotesis_nula = c("$H_0: \\rho = 0$", "$H_0: \\rho = 0$", "$H_0: \\rho = 0$"),
  Hipotesis_alternativa = c("$H_1: \\rho \\neq 0$", "$H_1: \\rho \\neq 0$", "$H_1: \\rho \\neq 0$"),
  Nivel_significancia = rep("0.05", 3),
  Valor_t = c(cor_test_1$statistic, cor_test_2$statistic, cor_test_3$statistic),
  df = rep(cor_test_1$parameter, 3),  # Grados de libertad
  Valor_p = c(cor_test_1$p.value, cor_test_2$p.value, cor_test_3$p.value),
  Comparacion = c(
    ifelse(cor_test_1$p.value < alpha, "Valor p < alfa", "Valor p > alfa"),
    ifelse(cor_test_2$p.value < alpha, "Valor p < alfa", "Valor p > alfa"),
    ifelse(cor_test_3$p.value < alpha, "Valor p < alfa", "Valor p > alfa")
  ),
  Decisi贸n = c(
    ifelse(cor_test_1$p.value < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$"),
    ifelse(cor_test_2$p.value < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$"),
    ifelse(cor_test_3$p.value < alpha, "Rechazamos $H_0$", "No rechazamos $H_0$")
  ),
  stringsAsFactors = FALSE
)

hipotesis_table_correlacion <- hipotesis_table_correlacion[, -2]

library(knitr)
library(kableExtra)
kable(hipotesis_table_correlacion, "html", caption = "Prueba de Hip贸tesis para los Coeficientes de Correlaci贸n de Pearson", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE, position = "center")
```

Los resultados de la prueba de hip贸tesis para los coeficientes de correlaci贸n de Pearson entre las variables independientes y la variable dependiente muestran que todas las variables, Distancia_km, Num_Paquetes y Velocidad_Trafico, tienen un valor p mucho menor que el nivel de significancia est谩ndar de 0.05. Esto indica que todas las variables tienen una relaci贸n lineal significativa con el Tiempo_Entrega_min.

La correlaci贸n entre Distancia_km y Tiempo_Entrega_min es fuerte, con un valor t de 5.39 y un valor p de 0.0000404, lo que muestra una relaci贸n positiva significativa. De manera similar, Num_Paquetes tambi茅n tiene una correlaci贸n significativa, con un valor t de 6.86 y un valor p de 0.0000020. Finalmente, Velocidad_Trafico tambi茅n tiene una relaci贸n significativa, aunque con una correlaci贸n un poco m谩s baja en comparaci贸n con las otras dos variables, mostrando un valor t de 4.46 y un valor p de 0.00003048.

Aunque todas las variables muestran una relaci贸n significativa con el tiempo de entrega, es importante notar que, en la prueba de hip贸tesis de los coeficientes en el modelo de regresi贸n, solo Num_Paquetes fue estad铆sticamente significativa. Esto puede sugerir que, cuando se consideran todas las variables de manera conjunta, el impacto de Distancia_km y Velocidad_Trafico se ve atenuado por la presencia de otras variables en el modelo, mientras que Num_Paquetes sigue siendo el factor m谩s relevante para predecir el tiempo de entrega.


# **10. Validaci贸n de los supuestos**

## **Linealidad**

Para validar el supuesto de linealidad en nuestro modelo de regresi贸n, utilizaremos un gr谩fico que muestra los residuos en funci贸n de los ajustes (valores predichos), si la relaci贸n entre las variables independientes y la variable dependiente es lineal, los puntos en el gr谩fico deben distribuirse aleatoriamente alrededor de la l铆nea horizontal en cero, sin formar patrones espec铆ficos, un patr贸n sistem谩tico en este gr谩fico podr铆a indicar que la relaci贸n no es lineal, lo que sugerir铆a que el modelo de regresi贸n lineal no es el m谩s adecuado para los datos.

```{r}
# Gr谩fico de residuos vs ajustes para verificar la linealidad
plot(modelo$fitted.values, modelo$residuals, 
     main = "Residuos vs Ajustes", 
     xlab = "Ajustes (Valores Predichos)", 
     ylab = "Residuos", 
     pch = 16, col = "blue")
abline(h = 0, col = "red", lwd = 2)
```

Como se observa, en el gr谩fico de Residuos vs Ajustes, los puntos se distribuyen de manera aleatoria alrededor de la l铆nea horizontal en cero, sin un patr贸n claro, lo que sugiere que la relaci贸n entre las variables independientes y la variable dependiente es probablemente lineal. No se observan patrones ni dispersi贸n creciente o decreciente, lo que apoya la validez del supuesto de linealidad en el modelo de regresi贸n. Esto tambi茅n se refleja en los resultados de la correlaci贸n de Pearson, donde todas las variables independientes muestran correlaciones directas con el tiempo de entrega, lo que refuerza la relaci贸n lineal entre ellas y la variable dependiente.

## **Normalidad**

```{r}
# Obtener los residuos del modelo
residuos <- residuals(modelo)

# Graficar el gr谩fico Q-Q
qqnorm(residuos, main = "Gr谩fico Q-Q de los Residuos", col = "blue", pch = 19)
qqline(residuos, col = "red", lwd = 2)  
```

En el gr谩fico Q-Q de los residuos, los puntos siguen bastante bien la l铆nea roja, lo que sugiere que los residuos se distribuyen de forma normal. Sin embargo, se puede notar que en las colas (extremos), los puntos est谩n un poco m谩s alejados de la l铆nea, lo que podr铆a indicar una ligera desviaci贸n de la normalidad en esas zonas. A pesar de esto, el ajuste general sigue siendo adecuado, lo que sugiere que el supuesto de normalidad no se ve afectado de manera significativa. Lo anterior, lo podemos verficar en mayor medida con la prueba de Shapiro Wilk para los residuos, dado que contamos con una muestra inferior a los 50 datos.

**1. Formulaci贸n de hip贸tesis**

- **Hip贸tesis nula (\(H_0\))**: Los residuos siguen una distribuci贸n normal.
- **Hip贸tesis alternativa (\(H_1\))**: Los residuos no siguen una distribuci贸n normal.

**2. Nivel de significancia**

Se ha utilizado un nivel de significancia de $\alpha = 0.05$.

**3-4. Estad铆stico de prueba y valor p**

```{r}
# Realizar el test de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
shapiro_test
```

**5. Comparaci贸n de valor p y nivel de significancia**

Si el $p$-valor es igual a 0.3319 y el nivel de significancia $\alpha$ es 0.05, entonces comparamos:  $p$-valor > $\alpha$, lo que nos lleva a concluir que no rechazamos la hip贸tesis nula ($H_0$).

**6. Conclusi贸n**

El resultado del test de Shapiro-Wilk para los residuos muestra un valor W = 0.94758 y un p-value = 0.3319. Esto indica que, dado el p-valor mayor a 0.05, no tenemos evidencia suficiente para rechazar la hip贸tesis nula de que los residuos siguen una distribuci贸n normal. En otras palabras, podemos concluir que no hay indicios de que los residuos no sean normales, lo cual apoya el supuesto de normalidad en el modelo de regresi贸n.

## **Multicolinealidad**

Para detectar la multicolinealidad, utilizaremos una matriz de correlaci贸n, que nos ayudar谩 a identificar si alguna de las variables independientes presenta una alta correlaci贸n con otras, si se encuentran correlaciones superiores a 0.7 o menores a -0.7, podr铆a ser un indicio de multicolinealidad.

```{r}
correlaciones %>%
  kable("html", caption = "Matriz de Correlaci贸n entre las Variables", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE, position = "center")
```

1. Distancia_km ~ Num_Paquetes: Con un valor de 0.8236, la asociaci贸n lineal es alta, lo que sugiere una fuerte relaci贸n entre estas dos variables.

2. Distancia_km ~ Velocidad_Trafico: El valor de 0.8226 tambi茅n indica una alta correlaci贸n, lo que muestra una asociaci贸n lineal considerable entre estas dos variables.

3. Distancia_km ~ Tiempo_Entrega_min: El valor de 0.7857 sugiere igualmente una correlaci贸n alta, lo que implica una relaci贸n lineal significativa con la variable dependiente.

De esta manera, todas las variables independientes tienen asociaciones lineales altas entre s铆, lo que podr铆a indicar multicolinealidad. Esto es importante porque la multicolinealidad puede afectar la interpretaci贸n de los coeficientes en un modelo de regresi贸n, ya que estas variables podr铆an estar explicando en gran parte lo mismo.

## **Autocorrelaci贸n**

**1. Formulaci贸n de hip贸tesis**

- **Hip贸tesis nula (\(H_0\))**: No existe autocorrelaci贸n en los residuos (es decir, los residuos son independientes).
- **Hip贸tesis alternativa (\(H_1\))**: Existe autocorrelaci贸n en los residuos (los residuos no son independientes).

**2. Nivel de significancia**

Se ha utilizado un nivel de significancia de $\alpha = 0.05$.

**3-4. Estad铆stico de prueba y valor p**

```{r, warning=FALSE}
# Realizar el test de Durbin-Watson
dw_test <- dwtest(modelo, alternative = "two.sided")
dw_test
```

**5. Comparaci贸n de valor p y nivel de significancia**

Dado que el $p$-valor es $0.9398$ y el nivel de significancia es $\alpha = 0.05$, comparamos ambos valores y concluimos que, ya que $p$-valor > $\alpha$, no rechazamos la hip贸tesis nula ($H_0$).

**6. Conclusi贸n**

La prueba de Durbin-Watson con un p-valor de 0.9398 sugiere que no rechazamos la hip贸tesis nula de que los residuos se comportan de manera independiente. Como el p-valor es mayor que el nivel de significancia de 0.05, no hay suficiente evidencia para indicar que los residuos est茅n correlacionados, lo que significa que se distribuyen de forma independiente, validando as铆 este supuesto en el modelo de regresi贸n.

## **Homocedasticidad**

Para verificar la homocedasticidad, realizaremos dos pruebas: la de Godfrey y la de Breusch-Pagan. Ambas pruebas sirven para evaluar si la varianza de los residuos es constante, lo que es clave para validar el supuesto de homocedasticidad en un modelo de regresi贸n. La diferencia principal entre ellas es que la prueba de Godfrey se enfoca m谩s en la autocorrelaci贸n de los residuos, mientras que la prueba de Breusch-Pagan eval煤a si la varianza de los residuos cambia sistem谩ticamente con los valores predichos. Al aplicar ambas pruebas, podemos tener m谩s seguridad de que no existe heterocedasticidad en nuestro modelo.

**1. Formulaci贸n de hip贸tesis**

- **Hip贸tesis nula (\(H_0\))**: Varianza de los residuos es constante (homocedasticidad).
- **Hip贸tesis alternativa (\(H_1\))**: Varianza de los residuos no es constante (heterocedasticidad).

**2. Nivel de significancia**

Se ha utilizado un nivel de significancia de $\alpha = 0.05$.

**3-4. Estad铆stico de prueba y valor p**

**Breusch-Pagan**

```{r}
bptest(modelo)
```

**Godfrey**

```{r}
bgtest(modelo)
```

**5. Comparaci贸n de valor p y nivel de significancia**

**Breusch-Pagan**

Si el $p$-valor es $0.9398$ y el nivel de significancia $\alpha = 0.05$, comparamos ambos valores. Dado que $p$-valor > $\alpha$, concluimos que no rechazamos la hip贸tesis nula ($H_0$).

**Godfrey**

Dado que el $p$-valor es $0.6735$ y el nivel de significancia es $\alpha = 0.05$, comparamos ambos valores y concluimos que, ya que $p$-valor > $\alpha$, no rechazamos la hip贸tesis nula ($H_0$).


**6. Conclusi贸n**

**Breusch-Pagan**

La prueba de Breusch-Pagan con un $p$-valor de $0.9398$ sugiere que no rechazamos la hip贸tesis nula de homocedasticidad. Dado que el p-valor es mayor que el nivel de significancia de 0.05, no hay suficiente evidencia para indicar que existe heterocedasticidad en los residuos, lo que implica que la varianza de los residuos se mantiene constante a lo largo de las observaciones y valida este supuesto en el modelo de regresi贸n.

**Godfrey**

La prueba de Godfrey, con un $p$-valor de $0.6735$ y un nivel de significancia de $\alpha = 0.05$, indica que no hay evidencia suficiente para rechazar la hip贸tesis nula. Esto sugiere que no hay autocorrelaci贸n en los residuos del modelo, ya que el $p$-valor es mayor que el nivel de significancia. Por lo tanto, podemos concluir que los residuos se comportan de manera independiente, lo que valida este supuesto en el modelo de regresi贸n.





